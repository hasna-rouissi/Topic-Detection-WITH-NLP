{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b199fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Chargement du dataset r√©duit et des embeddings...\n",
      "‚úÖ Dataset : 30000 lignes\n",
      "‚úÖ Embeddings : (30000, 384)\n",
      "\n",
      "‚öôÔ∏è D√©tection de la nouveaut√© (batch-wise)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30000/30000 [16:12<00:00, 30.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Colonne 'label' ajout√©e avec succ√®s !\n",
      "label\n",
      "1    17051\n",
      "0    12949\n",
      "Name: count, dtype: int64\n",
      "üíæ Dataset sauvegard√© dans : C:\\Users\\hasna\\Desktop\\Master\\S3\\NLP\\Projet-NLP\\data\\data_small_with_labels.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PY</th>\n",
       "      <th>id</th>\n",
       "      <th>eid</th>\n",
       "      <th>TI</th>\n",
       "      <th>author</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>embedding_index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>85058550296</td>\n",
       "      <td>2-s2.0-85058550296</td>\n",
       "      <td>knowledge capture and reuse through expert‚Äôs a...</td>\n",
       "      <td>[{'@_fa': 'true', '@seq': '1', 'author-url': '...</td>\n",
       "      <td>knowledge capture reuse expert activity monito...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>85058873457</td>\n",
       "      <td>2-s2.0-85058873457</td>\n",
       "      <td>an approach of energy resources control system...</td>\n",
       "      <td>[{'@_fa': 'true', '@seq': '1', 'author-url': '...</td>\n",
       "      <td>approach energy resource control system design</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>85058993388</td>\n",
       "      <td>2-s2.0-85058993388</td>\n",
       "      <td>som-like neural network and differential evolu...</td>\n",
       "      <td>[{'@_fa': 'true', '@seq': '1', 'author-url': '...</td>\n",
       "      <td>som like neural network differential evolution...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>85059318297</td>\n",
       "      <td>2-s2.0-85059318297</td>\n",
       "      <td>drug discovery and drug marketing with the cri...</td>\n",
       "      <td>[{'@_fa': 'true', '@seq': '1', 'author-url': '...</td>\n",
       "      <td>drug discovery drug marketing critical role mo...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>85059937495</td>\n",
       "      <td>2-s2.0-85059937495</td>\n",
       "      <td>towards a natural language compiler</td>\n",
       "      <td>[{'@_fa': 'true', '@seq': '1', 'author-url': '...</td>\n",
       "      <td>towards natural language compiler</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018</td>\n",
       "      <td>85044445280</td>\n",
       "      <td>2-s2.0-85044445280</td>\n",
       "      <td>spontaneous emergence of programs from ‚Äúprimor...</td>\n",
       "      <td>[{'@_fa': 'true', '@seq': '1', 'author-url': '...</td>\n",
       "      <td>spontaneous emergence program primordial soup ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018</td>\n",
       "      <td>85044714101</td>\n",
       "      <td>2-s2.0-85044714101</td>\n",
       "      <td>towards high-performance python</td>\n",
       "      <td>[{'@_fa': 'true', '@seq': '1', 'author-url': '...</td>\n",
       "      <td>towards high performance python</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018</td>\n",
       "      <td>85045383599</td>\n",
       "      <td>2-s2.0-85045383599</td>\n",
       "      <td>the online set aggregation problem</td>\n",
       "      <td>[{'@_fa': 'true', '@seq': '1', 'author-url': '...</td>\n",
       "      <td>online set aggregation problem</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018</td>\n",
       "      <td>85045426562</td>\n",
       "      <td>2-s2.0-85045426562</td>\n",
       "      <td>practical, anonymous, and publicly linkable un...</td>\n",
       "      <td>[{'@_fa': 'true', '@seq': '1', 'author-url': '...</td>\n",
       "      <td>practical anonymous publicly linkable universa...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018</td>\n",
       "      <td>85046626398</td>\n",
       "      <td>2-s2.0-85046626398</td>\n",
       "      <td>a distributional semantics model for idiom det...</td>\n",
       "      <td>[{'@_fa': 'true', '@seq': '1', 'author-url': '...</td>\n",
       "      <td>distributional semantics model idiom detection...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PY           id                 eid  \\\n",
       "0  2018  85058550296  2-s2.0-85058550296   \n",
       "1  2018  85058873457  2-s2.0-85058873457   \n",
       "2  2018  85058993388  2-s2.0-85058993388   \n",
       "3  2018  85059318297  2-s2.0-85059318297   \n",
       "4  2018  85059937495  2-s2.0-85059937495   \n",
       "5  2018  85044445280  2-s2.0-85044445280   \n",
       "6  2018  85044714101  2-s2.0-85044714101   \n",
       "7  2018  85045383599  2-s2.0-85045383599   \n",
       "8  2018  85045426562  2-s2.0-85045426562   \n",
       "9  2018  85046626398  2-s2.0-85046626398   \n",
       "\n",
       "                                                  TI  \\\n",
       "0  knowledge capture and reuse through expert‚Äôs a...   \n",
       "1  an approach of energy resources control system...   \n",
       "2  som-like neural network and differential evolu...   \n",
       "3  drug discovery and drug marketing with the cri...   \n",
       "4                towards a natural language compiler   \n",
       "5  spontaneous emergence of programs from ‚Äúprimor...   \n",
       "6                    towards high-performance python   \n",
       "7                 the online set aggregation problem   \n",
       "8  practical, anonymous, and publicly linkable un...   \n",
       "9  a distributional semantics model for idiom det...   \n",
       "\n",
       "                                              author  \\\n",
       "0  [{'@_fa': 'true', '@seq': '1', 'author-url': '...   \n",
       "1  [{'@_fa': 'true', '@seq': '1', 'author-url': '...   \n",
       "2  [{'@_fa': 'true', '@seq': '1', 'author-url': '...   \n",
       "3  [{'@_fa': 'true', '@seq': '1', 'author-url': '...   \n",
       "4  [{'@_fa': 'true', '@seq': '1', 'author-url': '...   \n",
       "5  [{'@_fa': 'true', '@seq': '1', 'author-url': '...   \n",
       "6  [{'@_fa': 'true', '@seq': '1', 'author-url': '...   \n",
       "7  [{'@_fa': 'true', '@seq': '1', 'author-url': '...   \n",
       "8  [{'@_fa': 'true', '@seq': '1', 'author-url': '...   \n",
       "9  [{'@_fa': 'true', '@seq': '1', 'author-url': '...   \n",
       "\n",
       "                                          clean_text  embedding_index  label  \n",
       "0  knowledge capture reuse expert activity monito...                0      1  \n",
       "1     approach energy resource control system design                1      1  \n",
       "2  som like neural network differential evolution...                2      1  \n",
       "3  drug discovery drug marketing critical role mo...                3      1  \n",
       "4                  towards natural language compiler                4      1  \n",
       "5  spontaneous emergence program primordial soup ...                5      1  \n",
       "6                    towards high performance python                6      1  \n",
       "7                     online set aggregation problem                7      1  \n",
       "8  practical anonymous publicly linkable universa...                8      1  \n",
       "9  distributional semantics model idiom detection...                9      1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Objectif : D√©tection de la nouveaut√© √† partir des embeddings\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity #mesurer la similarit√© entre deux embeddings\n",
    "from tqdm import tqdm #afficher une barre de progression pendant les boucles\n",
    "import os\n",
    "\n",
    "# === Chargement des donn√©es ===\n",
    "DATA_PATH = r\"C:\\Users\\hasna\\Desktop\\Master\\S3\\NLP\\Projet-NLP\\data\"\n",
    "\n",
    "print(\" Chargement du dataset r√©duit et des embeddings...\")\n",
    "df = pd.read_csv(os.path.join(DATA_PATH, \"data_small_with_embeddings.csv\"))\n",
    "embeddings = np.load(os.path.join(DATA_PATH, \"embeddings_small_minilm.npy\"))\n",
    "\n",
    "print(f\" Dataset : {df.shape[0]} lignes\")\n",
    "print(f\" Embeddings : {embeddings.shape}\")\n",
    "\n",
    "# === D√©tection de la nouveaut√© batch-wise ===\n",
    "\n",
    "# Le seuil (threshold) d√©termine √† partir de quelle similarit√© on consid√®re un article comme ‚Äúr√©p√©titif‚Äù ou ‚Äúnouveau‚Äù\n",
    "#Si la similarit√© max < 0.60 ‚Üí nouveau (label = 1)\n",
    "#Si la similarit√© max ‚â• 0.60 ‚Üí r√©p√©titif (label = 0)\n",
    "#plus haut ‚Üí plus d‚Äôarticles consid√©r√©s ‚Äúsimilaires‚Äù\n",
    "#plus bas ‚Üí plus d‚Äôarticles consid√©r√©s ‚Äúnouveaux‚Äù\n",
    "\n",
    "plus bas ‚Üí plus d‚Äôarticles consid√©r√©s ‚Äúnouveaux‚Äù\n",
    "threshold = 0.60\n",
    "labels = []\n",
    "\n",
    "print(\"\\n D√©tection de la nouveaut√© (batch-wise)...\")\n",
    "\n",
    "#Boucle principale de d√©tection\n",
    "\n",
    "for i in tqdm(range(len(embeddings))):\n",
    "    if i == 0:\n",
    "        labels.append(1)  # le premier texte est toujours \"nouveau\"\n",
    "    else:\n",
    "        #Pour chaque article (embedding[i]), on le compare √† tous les articles pr√©c√©dents.\n",
    "        previous_embeddings = embeddings[:i]\n",
    "        sim = cosine_similarity(       #On calcule la similarit√© cosinus entre le vecteur courant et les pr√©c√©dents.\n",
    "            embeddings[i].reshape(1, -1),\n",
    "            previous_embeddings\n",
    "        )\n",
    "        max_sim = np.max(sim) #On r√©cup√®re la plus grande similarit√© trouv√©e (max_sim)\n",
    "        if max_sim < threshold:\n",
    "            labels.append(1)  # nouveau\n",
    "        else:\n",
    "            labels.append(0)  # similaire √† un texte existant\n",
    "\n",
    "# Ajout de la colonne \"label\"\n",
    "df[\"label\"] = labels\n",
    "print(\"\\n Colonne 'label' ajout√©e avec succ√®s !\")\n",
    "print(df[\"label\"].value_counts())\n",
    "\n",
    "# === Sauvegarde du dataset enrichi ===\n",
    "\n",
    "output_file = os.path.join(DATA_PATH, \"data_small_with_labels.csv\")\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\" Dataset sauvegard√© dans : {output_file}\")\n",
    "\n",
    "# === Aper√ßu ===\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d2200d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6eed74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (st-cpu)",
   "language": "python",
   "name": "st-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
